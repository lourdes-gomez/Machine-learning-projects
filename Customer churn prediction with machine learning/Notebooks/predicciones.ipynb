{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r'C:\\Users\\lour2\\Desktop\\LOURDES\\data science\\Proyecto Machine Learning\\my_model.pkl'\n",
    "\n",
    "\n",
    "\n",
    "with open(file_path, 'rb') as archivo_entrada:    #rb 'read bytes'\n",
    "    modelo_importado = pickle.load(archivo_entrada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\lour2\\Desktop\\LOURDES\\data science\\Proyecto Machine Learning\\data\\processed\\X_train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.881078</td>\n",
       "      <td>-0.882690</td>\n",
       "      <td>-0.528699</td>\n",
       "      <td>1.010604</td>\n",
       "      <td>-0.875800</td>\n",
       "      <td>1.123151</td>\n",
       "      <td>-0.983902</td>\n",
       "      <td>-1.095853</td>\n",
       "      <td>-0.562826</td>\n",
       "      <td>-0.879784</td>\n",
       "      <td>0.879784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.284263</td>\n",
       "      <td>1.132901</td>\n",
       "      <td>-0.528699</td>\n",
       "      <td>1.010604</td>\n",
       "      <td>1.141814</td>\n",
       "      <td>1.123151</td>\n",
       "      <td>1.016361</td>\n",
       "      <td>0.912532</td>\n",
       "      <td>-0.562826</td>\n",
       "      <td>-0.879784</td>\n",
       "      <td>0.879784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.793997</td>\n",
       "      <td>-0.882690</td>\n",
       "      <td>1.891436</td>\n",
       "      <td>-0.989507</td>\n",
       "      <td>-0.875800</td>\n",
       "      <td>-0.890352</td>\n",
       "      <td>-0.983902</td>\n",
       "      <td>-1.095853</td>\n",
       "      <td>-0.562826</td>\n",
       "      <td>1.136643</td>\n",
       "      <td>-1.136643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.344587</td>\n",
       "      <td>1.132901</td>\n",
       "      <td>-0.528699</td>\n",
       "      <td>1.010604</td>\n",
       "      <td>1.141814</td>\n",
       "      <td>-0.890352</td>\n",
       "      <td>1.016361</td>\n",
       "      <td>-1.095853</td>\n",
       "      <td>1.776747</td>\n",
       "      <td>-0.879784</td>\n",
       "      <td>0.879784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.079985</td>\n",
       "      <td>1.132901</td>\n",
       "      <td>-0.528699</td>\n",
       "      <td>-0.989507</td>\n",
       "      <td>1.141814</td>\n",
       "      <td>1.123151</td>\n",
       "      <td>1.016361</td>\n",
       "      <td>0.912532</td>\n",
       "      <td>-0.562826</td>\n",
       "      <td>-0.879784</td>\n",
       "      <td>0.879784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7265</th>\n",
       "      <td>-1.284263</td>\n",
       "      <td>-0.882690</td>\n",
       "      <td>-0.528699</td>\n",
       "      <td>1.010604</td>\n",
       "      <td>1.141814</td>\n",
       "      <td>-0.890352</td>\n",
       "      <td>1.016361</td>\n",
       "      <td>0.912532</td>\n",
       "      <td>-0.562826</td>\n",
       "      <td>-0.879784</td>\n",
       "      <td>0.879784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7266</th>\n",
       "      <td>-0.666905</td>\n",
       "      <td>1.132901</td>\n",
       "      <td>-0.528699</td>\n",
       "      <td>1.010604</td>\n",
       "      <td>-0.875800</td>\n",
       "      <td>-0.890352</td>\n",
       "      <td>-0.983902</td>\n",
       "      <td>0.912532</td>\n",
       "      <td>-0.562826</td>\n",
       "      <td>-0.879784</td>\n",
       "      <td>0.879784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7267</th>\n",
       "      <td>0.194243</td>\n",
       "      <td>1.132901</td>\n",
       "      <td>-0.528699</td>\n",
       "      <td>1.010604</td>\n",
       "      <td>1.141814</td>\n",
       "      <td>-0.890352</td>\n",
       "      <td>-0.983902</td>\n",
       "      <td>0.912532</td>\n",
       "      <td>-0.562826</td>\n",
       "      <td>-0.879784</td>\n",
       "      <td>0.879784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7268</th>\n",
       "      <td>-1.131708</td>\n",
       "      <td>1.132901</td>\n",
       "      <td>-0.528699</td>\n",
       "      <td>1.010604</td>\n",
       "      <td>-0.875800</td>\n",
       "      <td>1.123151</td>\n",
       "      <td>1.016361</td>\n",
       "      <td>0.912532</td>\n",
       "      <td>-0.562826</td>\n",
       "      <td>-0.879784</td>\n",
       "      <td>0.879784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7269</th>\n",
       "      <td>-1.229446</td>\n",
       "      <td>-0.882690</td>\n",
       "      <td>-0.528699</td>\n",
       "      <td>1.010604</td>\n",
       "      <td>-0.875800</td>\n",
       "      <td>1.123151</td>\n",
       "      <td>-0.983902</td>\n",
       "      <td>0.912532</td>\n",
       "      <td>-0.562826</td>\n",
       "      <td>-0.879784</td>\n",
       "      <td>0.879784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7270 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0     0.881078 -0.882690 -0.528699  1.010604 -0.875800  1.123151 -0.983902   \n",
       "1    -1.284263  1.132901 -0.528699  1.010604  1.141814  1.123151  1.016361   \n",
       "2    -0.793997 -0.882690  1.891436 -0.989507 -0.875800 -0.890352 -0.983902   \n",
       "3    -0.344587  1.132901 -0.528699  1.010604  1.141814 -0.890352  1.016361   \n",
       "4    -1.079985  1.132901 -0.528699 -0.989507  1.141814  1.123151  1.016361   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "7265 -1.284263 -0.882690 -0.528699  1.010604  1.141814 -0.890352  1.016361   \n",
       "7266 -0.666905  1.132901 -0.528699  1.010604 -0.875800 -0.890352 -0.983902   \n",
       "7267  0.194243  1.132901 -0.528699  1.010604  1.141814 -0.890352 -0.983902   \n",
       "7268 -1.131708  1.132901 -0.528699  1.010604 -0.875800  1.123151  1.016361   \n",
       "7269 -1.229446 -0.882690 -0.528699  1.010604 -0.875800  1.123151 -0.983902   \n",
       "\n",
       "             7         8         9        10  \n",
       "0    -1.095853 -0.562826 -0.879784  0.879784  \n",
       "1     0.912532 -0.562826 -0.879784  0.879784  \n",
       "2    -1.095853 -0.562826  1.136643 -1.136643  \n",
       "3    -1.095853  1.776747 -0.879784  0.879784  \n",
       "4     0.912532 -0.562826 -0.879784  0.879784  \n",
       "...        ...       ...       ...       ...  \n",
       "7265  0.912532 -0.562826 -0.879784  0.879784  \n",
       "7266  0.912532 -0.562826 -0.879784  0.879784  \n",
       "7267  0.912532 -0.562826 -0.879784  0.879784  \n",
       "7268  0.912532 -0.562826 -0.879784  0.879784  \n",
       "7269  0.912532 -0.562826 -0.879784  0.879784  \n",
       "\n",
       "[7270 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = np.array(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lour2\\miniconda3\\envs\\deep_learning\\lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "predictions = modelo_importado.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 3314, 1: 3956}\n"
     ]
    }
   ],
   "source": [
    "valores_unicos, cuentas = np.unique(predictions, return_counts=True)\n",
    "\n",
    "# Combina los valores Ãºnicos y las cuentas en un diccionario\n",
    "conteo_dict = dict(zip(valores_unicos, cuentas))\n",
    "\n",
    "# Imprime el resultado\n",
    "print(conteo_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
